# ScribeLens ğŸ”

Your documents. Your rules. AI that respects privacy.

![Demo](public/Demo-gif.gif)

![Next.js](https://img.shields.io/badge/Next.js-000000?logo=nextdotjs&logoColor=white)
![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?logo=typescript&logoColor=white)
![TailwindCSS](https://img.shields.io/badge/TailwindCSS-38B2AC?logo=tailwind-css&logoColor=white)
![OpenAI](https://img.shields.io/badge/OpenAI-412991?logo=openai&logoColor=white)
![Privacy First](https://img.shields.io/badge/Privacy-First-brightgreen)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

## ScribeLens

ScribeLens is my first Generative AI + Retrieval-Augmented Generation (RAG) app, built to provide private, document-focused Q&A without relying on third-party chatbots. Users can upload PDFs, which are converted into embeddings and stored in a local vector store. When questions are asked, the system retrieves the most relevant passages and generates accurate, context-aware answers always grounded in the uploaded docs. With a Next.js App Router backend, OpenAI embeddings, and zero external storage (files are never saved, and embeddings are deleted permanently on request), ScribeLens ensures both speed and privacy. This project taught me the foundations of RAG systems, vector search, and ethical AI development.

ğŸ‘‰ **Live demo**: [https://scribe-lens.up.railway.app/](https://scribe-lens.up.railway.app/)  
ğŸ“‚ **Repo**: [github.com/Yasir-Rafique/scribe-lens](https://github.com/Yasir-Rafique/scribe-lens)

---

## âœ¨ Why ScribeLens

ScribeLens is built for **people who need fast, accurate answers from their own documents**
PhD students skimming research, lawyers reviewing contracts, teams searching specs, or students summarizing papers.

The focus is on **privacy, simplicity, and reliability** not being a one-size-fits-all chatbot.

---

## ğŸ”‘ Highlights

- ğŸ”’ **Privacy-first** â†’ PDFs are _not_ saved, only embeddings. Delete = permanent removal.
- âš¡ **VectorStore magic** â†’ embeddings enable fast & accurate retrieval.
- âš™ï¸ **Next.js App Router** â†’ clean API routes, server actions, streaming responses.
- ğŸ§© **Accurate retrieval** â†’ embeddings + keyword fallback + small heuristics.
- ğŸ’¬ **Natural answers** â†’ grounded in your docs, concise, and reference snippets included.

---

## ğŸ› ï¸ How it works (high level)

1. Upload a PDF.
2. Extract text â†’ split into refined chunks.
3. Create embeddings with OpenAI.
4. Store embeddings in a local vector store (`./vector/<pdfId>.json`).
5. Query â†’ embed the question â†’ retrieve nearest chunks â†’ pass context to LLM.
6. Answer is generated _only from your docs_ (no open web).

---

## ğŸš€ Features

- âœ… PDF upload & automatic chunking
- âœ… Embedding creation with OpenAI
- âœ… Local file-based vector store (MVP)
- âœ… Retrieval + Q&A with context snippets
- âœ… Keyword fallback & heuristics
- âœ… Document summarization fallback
- âœ… Front-matter boosting (title/author detection)
- âœ… Clean Next.js + Tailwind UI

---

## âš¡ Quickstart

### Requirements

- Node.js v18+
- OpenAI API key (`OPENAI_API_KEY`)

### Install

```bash
git clone https://github.com/Yasir-Rafique/scribe-lens.git
cd scribe-lens
npm install
```

### Environment

Create .env.local:

```bash
OPENAI_API_KEY=sk-...
```

### Run (dev)

```bash
npm run dev
http://localhost:3000
```

### Build / Production

```bash
npm run build
npm run start
```

## âš™ï¸ Design Choices

- Embedding model â†’ text-embedding-3-small (normalized).
- Vector store â†’ simple JSON per PDF (MVP).
- Retrieval logic â†’ cosine similarity + keyword fallback + heuristics.
- LLM prompts â†’ enforce context-only answers, concise replies, and reference listing.

## ğŸ”’ Privacy & Ethics

- ğŸš« PDFs are never stored. Only embeddings are created.
- ğŸ—‘ï¸ Delete = permanent removal. We cannot access deleted embeddings.
- ğŸ” Transparent: embeddings live in local JSON files.
- âœ… Ethical defaults: if answer not found, model politely says so (no hallucination).

âš ï¸ Note: Embeddings are local, but queries still call OpenAIâ€™s API.
Swap in self-hosted LLMs/embedding models if you need full local inference.

## ğŸ§° Troubleshooting

- Dimension mismatch â†’ re-upload PDF to regenerate embeddings.
- No text extracted â†’ PDF may be scanned; run OCR first.
- Vague answers â†’ system prompt enforces fallback message.

## ğŸ“œ License

MIT Â© 2025 Yasir Rafique

## ğŸ‘¤ Author

Muhammad Yasir Rafique
ğŸŒ GitHub: @Yasir-Rafique
ğŸš€ Live demo: https://scribe-lens.up.railway.app/

### âœ¨ Thanks for checking out ScribeLens - privacy-first RAG for people who care about accurate answers under their control. ğŸš€
